{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12647efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba996b",
   "metadata": {},
   "source": [
    "### Preparation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07b0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(texts_path, images_path):\n",
    "  \"\"\"Create dataframe with path to image and corresponding text description\"\"\"\n",
    "\n",
    "  texts_df = pd.read_csv(texts_path)\n",
    "  texts_df['text'] = texts_df['color'] + \" \" + texts_df['name'] + \" \" + texts_df['description']\n",
    "  texts_df = texts_df[['Unnamed: 0','text']]\n",
    "  \n",
    "  df = pd.DataFrame(columns=[\"Image\",\"Text\"])  \n",
    "    \n",
    "  for image in glob.glob(images_path):\n",
    "    img_name = os.path.basename(image)\n",
    "    key_img_name = img_name.split('_')[0]\n",
    "    img_descr = texts_df[texts_df['Unnamed: 0']==int(key_img_name)].iloc[0,-1]\n",
    "    df = df.append({'Image': img_name, 'Text':img_descr}, ignore_index=True)\n",
    "    \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fba569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97f3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Transformation of images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "# Transformation of texts\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "# Data paths\n",
    "descriptions_data = \"./processed_data/processedSKUs_nodups.csv\"\n",
    "images_folder = \"./processed_data/images/*.jpg\"\n",
    "img_dir = \"./processed_data/images/\"\n",
    "\n",
    "# Creation of organized dataframe\n",
    "annotations_file = create_dataset(descriptions_data, images_folder)\n",
    "\n",
    "# Creation of custom Dataset\n",
    "dataset = CustomImageDataset(annotations_file, img_dir, transform=transform)\n",
    "\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "#testloader = DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6936ca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " '18 Kt Rose Gold Supreme Swan Charm Bracelet The Supreme Swan Charm Bracelet is the symbol of love, peace and grace. Gift this to a loved one that adds these elements to your life. Made in Sterling Silver with a rose gold polish.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a1ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch CPU",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
