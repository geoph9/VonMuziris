{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "QtoYxZb3S5la"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fZCreGW3b-Eq"
   },
   "outputs": [],
   "source": [
    "def normalization(X):\n",
    "    \"\"\"L2-normalization of features columns\"\"\"\n",
    "    norm = torch.pow(X, 2).sum(dim=1, keepdim=True).sqrt()\n",
    "    X = torch.div(X, norm)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cVbV8r2fTFQv"
   },
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "\n",
    "  def __init__(self, embedding_size, cnn_type):\n",
    "    \"\"\"Initializing parameters\"\"\"\n",
    "    super(ImageEncoder).__init__()\n",
    "    self.embedding_size = embedding_size # Size of projected image\n",
    "    self.cnn = self.load_cnn(cnn_type)\n",
    "\n",
    "    # No need to finetune parameters = frozen layers\n",
    "    for param in self.cnn.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replacing last fully connected layer with new one\n",
    "    self.fc = nn.Linear(self.cnn.classifier._modules['6'].in_features, embedding_size)\n",
    "    self.cnn.classifier = nn.Sequential(*list(self.cnn.classifier.children())[:-1])\n",
    "\n",
    "    # Initializing the weights of fully-connected layer, which makes projection to new space\n",
    "    self.initialization_weights()\n",
    "  \n",
    "  def load_cnn(self, cnn_type):\n",
    "    \"\"\"Loading pretrained model\"\"\"\n",
    "    model = models.__dict__[cnn_type](pretrained=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "  def initialization_weights(self):\n",
    "    \"\"\"Xavier initialization\"\"\"\n",
    "    r = np.sqrt(6.) / np.sqrt(self.fc.in_features + self.fc.out_features)\n",
    "    self.fc.weight.data.uniform_(-r, r)\n",
    "    self.fc.bias.data.fill_(0)\n",
    "\n",
    "  def forward(self, X):\n",
    "    \"\"\"Creation of features\"\"\"\n",
    "    # Creation of embeddings\n",
    "    features = self.cnn(X)\n",
    "\n",
    "    # Normalization of embeddings\n",
    "    features = normalization(features)\n",
    "\n",
    "    # Projection to new space\n",
    "    features = self.fc(features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
